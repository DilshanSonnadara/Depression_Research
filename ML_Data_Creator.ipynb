{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data for ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Data/Visualization_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a representative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum percentage of the dataframe that can be sampled while being representative: 82%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This code evaluates the maximum percentage of a given dataframe that can be sampled \n",
    "while ensuring the sample is representative of the population distributions specified \n",
    "for two categorical variables: 'Uni_Year' and 'Study_Stream'. The representativeness \n",
    "is assessed using chi-squared goodness of fit tests. Sampling is done without replacement \n",
    "starting from 99% of the dataframe and reduced by 1% increments until the sample \n",
    "to represent the population (p-value > 0.05 for both variables).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the population data\n",
    "data_uni_year = pd.DataFrame({\n",
    "    'Uni_Year': ['Year 1', 'Year 2', 'Year 3', 'Year 4'],\n",
    "    'Counts': [680, 643, 552, 387]\n",
    "})\n",
    "\n",
    "data_study_stream = pd.DataFrame({\n",
    "    'Study_Stream': [\n",
    "        'Physical Science',\n",
    "        'Biological Science',\n",
    "        'Industrial Statistics and Mathematical Finance',\n",
    "        'Biochemistry & Molecular Biology'\n",
    "    ],\n",
    "    'Counts': [1099, 558, 379, 215]\n",
    "})\n",
    "\n",
    "def test_representativeness(df, population, variable):\n",
    "    \"\"\"\n",
    "    Perform a chi-squared goodness of fit test to compare the observed frequency distribution\n",
    "    of a categorical variable in a sample DataFrame against the expected frequency distribution\n",
    "    based on a given population DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Sample DataFrame containing the observed frequencies of the categorical variable.\n",
    "    - population (DataFrame): Population DataFrame with the expected counts of the categorical variable.\n",
    "    - variable (str): The name of the categorical variable to test.\n",
    "\n",
    "    Returns:\n",
    "    - float: The p-value from the chi-squared test, indicating if the observed distribution significantly\n",
    "             differs from the population distribution (p <= 0.05 indicates a significant difference).\n",
    "    \"\"\"\n",
    "    # Calculate observed frequencies from the sample\n",
    "    observed = df[variable].value_counts().sort_index()\n",
    "    \n",
    "    # Align the population data and calculate expected frequencies\n",
    "    expected = population.set_index(variable)['Counts']\n",
    "    total_population = expected.sum()\n",
    "    total_sample = observed.sum()\n",
    "    \n",
    "    # Adjust expected frequencies to match the sample size\n",
    "    expected = expected * (total_sample / total_population)\n",
    "    expected = expected.reindex(observed.index, fill_value=0)  # Ensure the indices match\n",
    "    \n",
    "    # Perform the chi-squared test\n",
    "    chi2, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "\n",
    "# Sampling and testing loop\n",
    "max_representative_sample = 0\n",
    "for percentage in range(99, 75, -1):\n",
    "    sample_df = df.sample(frac=percentage/100, replace=False, weights='Post_Stratification_Weight',random_state=42)\n",
    "    p_uni_year = test_representativeness(sample_df, data_uni_year, 'Uni_Year')\n",
    "    p_study_stream = test_representativeness(sample_df, data_study_stream, 'Study_Stream')\n",
    "    \n",
    "    if p_uni_year > 0.05 and p_study_stream > 0.05:\n",
    "        max_representative_sample = percentage\n",
    "        break\n",
    "\n",
    "print(f\"Maximum percentage of the dataframe that can be sampled while being representative: {max_representative_sample}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=82/100, replace=False, weights='Post_Stratification_Weight',random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discarding the useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to be removed\n",
    "columns_to_remove = [\n",
    "    \"Ethnicity\", \"Currently_Single\", \"Exercise_Days\", \"Family_Income\", \"Family_Interaction\", \n",
    "    \"Family_Visit_Frequency\", \"Job_Type\", \"Lecture_Preferance\", \"Life_Threats\", \"Living_Parents\", \n",
    "    \"Love_Affair_Not_Satisfied\", \"Parents_Employment\", \"Religion\", \"Residence_Type\", \"Sleep_Hours\", \n",
    "    \"Sports_Participation\", \"Uni_Entry_Attempt\", \"Smoke_Frequency\", \"Travel_Mode\"\n",
    "]\n",
    "\n",
    "# Remove specified columns\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the ordinal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Accomodation Satisfaction takes on the values 1,2,3,4,5. However, it is more discriminative in predicting \n",
    "depression if 1,2 were combined and 4,5 was combined.\n",
    "\"\"\"\n",
    "\n",
    "# Define a mapping function for Accommodation_Satisfaction\n",
    "def map_accommodation_satisfaction(value):\n",
    "    if value in [1, 2]:\n",
    "        return 1\n",
    "    elif value == 3:\n",
    "        return 2\n",
    "    elif value in [4, 5]:\n",
    "        return 3\n",
    "\n",
    "# Apply the mapping function to the Accommodation_Satisfaction column\n",
    "df['Accommodation_Satisfaction'] = df['Accommodation_Satisfaction'].apply(map_accommodation_satisfaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "The frequency of socializing takes on the values Less than once a month,\n",
    "Once a month, 2 to 3 times a month, Once a week, More than once a week.\n",
    "However, it is more discriminative in predicting \n",
    "depression if Less than once a month, Once a month were combined\n",
    "and Once a week, More than once a week was combined.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Mapping dictionary for Socializing_Frequency\n",
    "socializing_map = {\n",
    "    'Less than once a month': 1,\n",
    "    'Once a month': 1,\n",
    "    '2 to 3 times a month': 2,\n",
    "    'Once a week': 3,\n",
    "    'More than once a week': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Socializing_Frequency column\n",
    "df['Socializing_Frequency'] = df['Socializing_Frequency'].map(socializing_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "The frequency of socializing takes on the values Eat 3 meals a day but not necessarily a healthy diet,\n",
    "Nutritionally Balanced Diet, Unable to eat 3 meals a day, Mostly eating junk food, \n",
    "On a diet. However, it is more discriminative in predicting \n",
    "depression if Unable to eat 3 meals a day, Mostly eating junk food were combined (As they are unhealthy)\n",
    "and the rest of the categories were ordinally encoded from the least healthiest category to the most\n",
    "healthiest category.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Mapping dictionary for Meal_Type\n",
    "meal_type_map = {\n",
    "    'Eat 3 meals a day but not necessarily a healthy diet': 2,\n",
    "    'Nutritionally Balanced Diet': 4,\n",
    "    'Unable to eat 3 meals a day': 1,\n",
    "    'Mostly eating junk food': 1,\n",
    "    'On a diet': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Meal_Type column\n",
    "df['Meal_Type'] = df['Meal_Type'].map(meal_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for Alcohol_Frequency\n",
    "alcohol_frequency_map = {\n",
    "    'Never': 1,\n",
    "    'Rarely': 2,\n",
    "    'Occasionally': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Alcohol_Frequency column\n",
    "df['Alcohol_Frequency'] = df['Alcohol_Frequency'].map(alcohol_frequency_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for Travel_Time\n",
    "travel_time_map = {\n",
    "    'Less than 1 hour': 1,\n",
    "    'Between 1 and 3 hours': 2,\n",
    "    'Between 3 and 5 hours': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Travel_Time column\n",
    "df['Travel_Time'] = df['Travel_Time'].map(travel_time_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for Academic_Achievements_Satisfaction\n",
    "academic_achievements_map = {\n",
    "    'No': 1,\n",
    "    'Neither satisfied nor dissatisfied': 2,\n",
    "    'No GPA as of yet': 2,\n",
    "    'Yes': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Academic_Achievements_Satisfaction column\n",
    "df['Academic_Achievements_Satisfaction'] = df['Academic_Achievements_Satisfaction'].map(academic_achievements_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for Weight_Status\n",
    "weight_status_map = {\n",
    "    'Underweight': 1,\n",
    "    'Healthy Weight': 2,\n",
    "    'Overweight': 3,\n",
    "    'Obesity': 4\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Weight_Status column\n",
    "df['Weight_Status'] = df['Weight_Status'].map(weight_status_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the nominal categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of nominal categorical variables\n",
    "nominal_vars = [\n",
    "    'Sex', 'Sexual_Orientation', 'Uni_Year', 'Study_Stream', 'Academic_Program_Satisfaction', \n",
    "    'Societies_Participation', 'English_Difficulty', 'Ragging_Experience', 'Staff_Support_Perception', \n",
    "    'Awareness_Of_Help', 'Siblings', 'Financial_Support', 'Financial_Support_Duty', 'Family_Debts', \n",
    "    'Recent_Death', 'Family_Illness', 'Power_Cut_Impact', 'Home_Confinement', 'Medical_Access_Difficulty', \n",
    "    'Job_Loss_Family', 'Love_Affair_Satisfied', 'Never_Love', 'Separated'\n",
    "]\n",
    "\n",
    "# Apply dummy encoding to these variables\n",
    "df_encoded = pd.get_dummies(df, columns=nominal_vars, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for depression_status\n",
    "depression_status_map = {\n",
    "    'No MDD': 0,\n",
    "    'MDD': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to the depression_status column\n",
    "df_encoded['depression_status'] = df_encoded['depression_status'].map(depression_status_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns except 'depression_status' and the post stratification weight\n",
    "features = df_encoded.drop(['depression_status', 'Post_Stratification_Weight'], axis=1)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Create a new DataFrame with the normalized features\n",
    "# Ensure to include the 'depression_status' and 'Post_Stratification_Weight' back into the DataFrame\n",
    "df_normalized = pd.DataFrame(normalized_features, columns=features.columns)\n",
    "df_normalized['depression_status'] = df_encoded['depression_status'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
